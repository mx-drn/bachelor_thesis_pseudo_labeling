{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "first_implementation_of_BERT_on_kaggle_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "451d74fff388426dbca13d9f360450ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc45334ca2b741fe884d05f90172cf9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e31fb501c214ec58cd7039f6f329583",
              "IPY_MODEL_4e821ae8826041488aef38ef67c2012a"
            ]
          }
        },
        "fc45334ca2b741fe884d05f90172cf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e31fb501c214ec58cd7039f6f329583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78c0ce6a134e414fa933b57b1f0f531d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eba9315c5b6485aba7acf13c613b88c"
          }
        },
        "4e821ae8826041488aef38ef67c2012a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61259b0ef97d49eea95a160dbede1fa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:06&lt;00:00, 33.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4364d9457ad4f158e8f063857d8eb93"
          }
        },
        "78c0ce6a134e414fa933b57b1f0f531d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eba9315c5b6485aba7acf13c613b88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61259b0ef97d49eea95a160dbede1fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4364d9457ad4f158e8f063857d8eb93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbbf0ba27f7f4856b96463e2489da47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_554a8864f44245f1a9fecbc01802cda5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a33739129da4926892a4cfa267b554d",
              "IPY_MODEL_ba6592dc238c4e71ab7eb538fd4d4fa1"
            ]
          }
        },
        "554a8864f44245f1a9fecbc01802cda5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a33739129da4926892a4cfa267b554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_545efd615b37481fa56c04fedba2bb91",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e8b8c0c6a864c8680d79b7f48b6c768"
          }
        },
        "ba6592dc238c4e71ab7eb538fd4d4fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbfdd63848b144099570bd4217155e3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:02&lt;00:00, 13.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21dd89d581f64c75b59d98991da0bd50"
          }
        },
        "545efd615b37481fa56c04fedba2bb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e8b8c0c6a864c8680d79b7f48b6c768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbfdd63848b144099570bd4217155e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21dd89d581f64c75b59d98991da0bd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b68820c62d7403084c20b485441fdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c498612b657e4352963985cb392b209c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1362e288548a4d4f915088aac0f0a9d4",
              "IPY_MODEL_111719bce2de4954a2712238ee4cd9d9"
            ]
          }
        },
        "c498612b657e4352963985cb392b209c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1362e288548a4d4f915088aac0f0a9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_510d76be22504a6699966583e3f5d92f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df5f611f1b0849f898519422899bc051"
          }
        },
        "111719bce2de4954a2712238ee4cd9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d71ef8aae1944f9890378d3b4971f22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c70198692653451795f8b8efe603afbb"
          }
        },
        "510d76be22504a6699966583e3f5d92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df5f611f1b0849f898519422899bc051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d71ef8aae1944f9890378d3b4971f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c70198692653451795f8b8efe603afbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fc8cd3eb25742c3b90ba06ddf296c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b2ab1bbbc6944ae92e78f5cd792cb1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_370259196d7649fa82002755341fa61c",
              "IPY_MODEL_50dc818e25fb4e64b1c8ce029e95b829"
            ]
          }
        },
        "9b2ab1bbbc6944ae92e78f5cd792cb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "370259196d7649fa82002755341fa61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5813bb92689748ffb3a2f99b3823840d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fa6857381cb43de8b83e1830eac4446"
          }
        },
        "50dc818e25fb4e64b1c8ce029e95b829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7c494f1acc04dab923d9dd67fbc0822",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 19.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32526d9292c847f39b62cb0dbef2ca12"
          }
        },
        "5813bb92689748ffb3a2f99b3823840d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fa6857381cb43de8b83e1830eac4446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7c494f1acc04dab923d9dd67fbc0822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32526d9292c847f39b62cb0dbef2ca12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mx-drn/bachelor_thesis_pseudo_labeling/blob/main/first_implementation_of_BERT_on_kaggle_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hZO7R9TMzaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4812eaf0-1a0d-409b-83ea-d6b7b00e893a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 27.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 28.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLNtikhwX99e"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCt7gXW-i9yc"
      },
      "source": [
        "#print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMT5LWhkMzal"
      },
      "source": [
        "# needed imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import time\n",
        "\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from textwrap import wrap\n",
        "#import pytorch_lightning as pl\n",
        "\n",
        "from pylab import rcParams\n",
        "from matplotlib import rc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNZ7vslbMzal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c95994f-3461-439f-8238-a79cedbe57de"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# Use GPU\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug  1 16:17:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFRiZccwMzam"
      },
      "source": [
        "# Get an Overview over the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMmaEOMh1Fdh",
        "outputId": "aa675b0d-522e-4678-9265-0d86bd6a2646"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MIORSrKMzam",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fa92dc-4a0b-496c-81b6-3500199fc506"
      },
      "source": [
        "# import data\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Data/kaggle_data.csv\", names=['label', 'article'], encoding='latin-1')\n",
        "\n",
        "print(\"Overall distribution of the data and labels:\")\n",
        "print(data['label'].value_counts(ascending=True))\n",
        "print()\n",
        "\n",
        "all_lens = {\n",
        "    'positive': [],\n",
        "    'negative': [],\n",
        "    'neutral': []\n",
        "}\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    all_lens[row['label']].append(len(row['article']))\n",
        "print(\"General dataset size: \" + str(len(data)))\n",
        "\n",
        "print(\"\\nPositive Sentiment Mean Article Length: \" + str(sum(all_lens['positive'])/len(all_lens['positive'])))\n",
        "print(\"Positive Sentiment Max Article Length: \" + str(max(all_lens['positive'])))\n",
        "print()\n",
        "print(\"Neutral Sentiment Mean Article Length: \" + str(sum(all_lens['neutral'])/len(all_lens['neutral'])))\n",
        "print(\"Neutral Sentiment Max Article Length: \" + str(max(all_lens['neutral'])))\n",
        "print()\n",
        "print(\"Negative Sentiment Mean Article Length: \" + str(sum(all_lens['negative'])/len(all_lens['negative'])))\n",
        "print(\"Negative Sentiment Max Article Length: \" + str(max(all_lens['negative'])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall distribution of the data and labels:\n",
            "negative     604\n",
            "positive    1363\n",
            "neutral     2879\n",
            "Name: label, dtype: int64\n",
            "\n",
            "General dataset size: 4846\n",
            "\n",
            "Positive Sentiment Mean Article Length: 135.64783565663976\n",
            "Positive Sentiment Max Article Length: 298\n",
            "\n",
            "Neutral Sentiment Mean Article Length: 125.07224730809308\n",
            "Neutral Sentiment Max Article Length: 315\n",
            "\n",
            "Negative Sentiment Mean Article Length: 125.75662251655629\n",
            "Negative Sentiment Max Article Length: 296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC3riTPlMzan"
      },
      "source": [
        "## Have a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBvpwUFhMzan",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd59996-b72c-4cb0-eb87-0e82a893286f"
      },
      "source": [
        "print('Article:')\n",
        "print(data.iloc[13].article + \"\\n\")\n",
        "print('Label:')\n",
        "print(data.iloc[13].label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article:\n",
            "Finnish Talentum reports its operating profit increased to EUR 20.5 mn in 2005 from EUR 9.3 mn in 2004 , and net sales totaled EUR 103.3 mn , up from EUR 96.4 mn .\n",
            "\n",
            "Label:\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m91CGvaCWnjc",
        "outputId": "bfb3e8d2-9411-4f44-8dc5-0c9f37b45c56"
      },
      "source": [
        "label_names = list(set(data['label'].values))\n",
        "label_names.sort()\n",
        "\n",
        "print(\"All possible labels: \" + str(label_names))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All possible labels: ['negative', 'neutral', 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcQOnkcvMzan"
      },
      "source": [
        "### Test Data if BERT cased or uncased makes sense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuqn6Oc2Mzao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f5098a-7ef2-436a-b1bf-cc938c4ea4c9"
      },
      "source": [
        "uppercased_words_found = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    temp_article = row['article']\n",
        "    \n",
        "    for word in temp_article:\n",
        "        if len(word)>1 and word == word.upper():\n",
        "            uppercased_words_found.append(word)\n",
        "            \n",
        "print(uppercased_words_found)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_89-2sLiMzao"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "606mN-qUMzao"
      },
      "source": [
        "# normalize whitespace\n",
        "data['article'] = data['article'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "# remove punctuations except ?\n",
        "data['article'] = data['article'].apply(lambda x: re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJLYjtJIMzap"
      },
      "source": [
        "## Convert labels to more understandable -1,0,1 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIT7oXs_Mzap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "51246504-3e19-4ff8-8468-1ffca3ac27d2"
      },
      "source": [
        "new_labels = {\n",
        "    'positive': 2,\n",
        "    'negative': 0,\n",
        "    'neutral': 1\n",
        "}\n",
        "for index, row in data.iterrows():\n",
        "  data['label'].iloc[index] = new_labels[row['label']]\n",
        "data.head(2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>According to Gran  ,  the company has no plans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            article\n",
              "0     1  According to Gran  ,  the company has no plans...\n",
              "1     1  Technopolis plans to develop in stages an area..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ErARovQHVgA"
      },
      "source": [
        "## Build Pseudo Labeling Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgjsgVpfHbI8"
      },
      "source": [
        "def get_dataclass_distribution_of_unlabeled_data(data_class_size, X, y, random_state):\n",
        "  labeled_data_distribution = data_class_size/len(X)\n",
        "\n",
        "  X_unlabeled, X_labeled, y_unlabeled, y_labeled = train_test_split(X, y, test_size=labeled_data_distribution, random_state=random_state)\n",
        "\n",
        "  return {\n",
        "      'labeled_data': X_labeled,\n",
        "      'labeled_data_labels': y_labeled,\n",
        "      'unlabeled_data': X_unlabeled,\n",
        "      'unlabeled_data_labels': y_unlabeled\n",
        "  }"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpqv6yEqMzap"
      },
      "source": [
        "## Set tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc5vTsC1Mzap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "451d74fff388426dbca13d9f360450ff",
            "fc45334ca2b741fe884d05f90172cf9d",
            "8e31fb501c214ec58cd7039f6f329583",
            "4e821ae8826041488aef38ef67c2012a",
            "78c0ce6a134e414fa933b57b1f0f531d",
            "5eba9315c5b6485aba7acf13c613b88c",
            "61259b0ef97d49eea95a160dbede1fa3",
            "f4364d9457ad4f158e8f063857d8eb93",
            "fbbf0ba27f7f4856b96463e2489da47f",
            "554a8864f44245f1a9fecbc01802cda5",
            "2a33739129da4926892a4cfa267b554d",
            "ba6592dc238c4e71ab7eb538fd4d4fa1",
            "545efd615b37481fa56c04fedba2bb91",
            "1e8b8c0c6a864c8680d79b7f48b6c768",
            "cbfdd63848b144099570bd4217155e3b",
            "21dd89d581f64c75b59d98991da0bd50",
            "0b68820c62d7403084c20b485441fdd1",
            "c498612b657e4352963985cb392b209c",
            "1362e288548a4d4f915088aac0f0a9d4",
            "111719bce2de4954a2712238ee4cd9d9",
            "510d76be22504a6699966583e3f5d92f",
            "df5f611f1b0849f898519422899bc051",
            "7d71ef8aae1944f9890378d3b4971f22",
            "c70198692653451795f8b8efe603afbb",
            "8fc8cd3eb25742c3b90ba06ddf296c2f",
            "9b2ab1bbbc6944ae92e78f5cd792cb1c",
            "370259196d7649fa82002755341fa61c",
            "50dc818e25fb4e64b1c8ce029e95b829",
            "5813bb92689748ffb3a2f99b3823840d",
            "9fa6857381cb43de8b83e1830eac4446",
            "e7c494f1acc04dab923d9dd67fbc0822",
            "32526d9292c847f39b62cb0dbef2ca12"
          ]
        },
        "outputId": "1c375f6a-9812-48a2-9c9e-ea0438efea8d"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# Uncased -> Because case may express the sentiment but no uppercase word are given in the dataset as mentioned earlier"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "451d74fff388426dbca13d9f360450ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbbf0ba27f7f4856b96463e2489da47f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b68820c62d7403084c20b485441fdd1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fc8cd3eb25742c3b90ba06ddf296c2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMinlZ7PMzap"
      },
      "source": [
        "### Choose maximum token length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ3EHTwyMzaq",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "467e2dce-e293-4c93-9a2e-6080a54d25b3"
      },
      "source": [
        "token_lens = []\n",
        "for txt in data.article:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))\n",
        "    \n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW2I38KQMzaq"
      },
      "source": [
        "MAX_LEN = 100\n",
        "BATCH_SIZE = 8\n",
        "SEED = 1210"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcuqFPNNMzaq"
      },
      "source": [
        "# Split data into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjOsFIKMzaq"
      },
      "source": [
        "def split_data_into_train_test_val(X, y, val_size, random_state):\n",
        "    X_reduced, X_test, y_reduced, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_reduced, y_reduced, test_size=val_size, random_state=random_state)\n",
        "    \n",
        "    return {\n",
        "        'train': {\n",
        "            'X': list(X_train),\n",
        "            'y': list(y_train)\n",
        "        },\n",
        "        'val': {\n",
        "            'X': list(X_val),\n",
        "            'y': list(y_val)\n",
        "        },\n",
        "        'test': {\n",
        "            'X': list(X_test),\n",
        "            'y': list(y_test)\n",
        "        }\n",
        "    }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijpna4dYMzaq",
        "scrolled": true
      },
      "source": [
        "split_data = split_data_into_train_test_val(data['article'].values, data['label'].values, val_size=0.2, random_state=SEED)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpvWmDwhMzar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809dcabc-49a3-4181-fce6-297bd445b294"
      },
      "source": [
        "X_train = split_data['train']['X']\n",
        "X_test = split_data['test']['X']\n",
        "X_val = split_data['val']['X']\n",
        "y_train = split_data['train']['y']\n",
        "y_test = split_data['test']['y']\n",
        "y_val = split_data['val']['y']\n",
        "\n",
        "import collections, numpy\n",
        "\n",
        "\n",
        "\n",
        "print(\"Distribution train: \")\n",
        "print(collections.Counter(y_train))\n",
        "print(\"\\nDistribution val: \")\n",
        "print(collections.Counter(y_val))\n",
        "print(\"\\nDistribution test: \")\n",
        "print(collections.Counter(y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution train: \n",
            "Counter({1: 2068, 2: 999, 0: 421})\n",
            "\n",
            "Distribution val: \n",
            "Counter({1: 520, 2: 234, 0: 119})\n",
            "\n",
            "Distribution test: \n",
            "Counter({1: 291, 2: 130, 0: 64})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m32Ndw0wMzar"
      },
      "source": [
        "### Build data class for pytorch-Dataloader usage (Map-style dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxuAYV89Mzar"
      },
      "source": [
        "class BertData():\n",
        "    def __init__(self, article, label):\n",
        "        self.article = article\n",
        "        self.label = label\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = MAX_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.article)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        article = str(self.article[idx])\n",
        "        article = ' '.join(article.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            article,\n",
        "            None,\n",
        "            add_special_tokens = True,\n",
        "            max_length = MAX_LEN,\n",
        "            padding='max_length',\n",
        "            truncation='longest_first'\n",
        "        )\n",
        "\n",
        "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
        "        labels = torch.tensor(self.label[idx], dtype=torch.long)\n",
        "\n",
        "        return {'article': article,\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'targets': labels\n",
        "                }"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxQzGprxRZh9"
      },
      "source": [
        "training_set = BertData(article=X_train, label=y_train)\n",
        "validation_set = BertData(article=X_val, label=y_val)\n",
        "test_set = BertData(article=X_test, label=y_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzUqxLvuMzas"
      },
      "source": [
        "### Set pytorch data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NQd1PdkMzas"
      },
      "source": [
        "def get_dataloader(training_set, validation_set, test_set):\n",
        "    train_dataloader = DataLoader(\n",
        "            training_set,\n",
        "            shuffle=False,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_workers=4\n",
        "            )\n",
        "    val_dataloader = DataLoader(\n",
        "            validation_set,\n",
        "            shuffle=False,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_workers=4\n",
        "            )\n",
        "    test_dataloader = DataLoader(\n",
        "            test_set,\n",
        "            shuffle=False,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_workers=4\n",
        "            )\n",
        "    \n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3dkrCVMzas"
      },
      "source": [
        "# BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYDrusWdMzat"
      },
      "source": [
        "## Build PyTorch Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUL8xhXYMzat"
      },
      "source": [
        "#train_dataloader, val_dataloader, test_dataloader = get_dataloader(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVyE_LGsMzat"
      },
      "source": [
        "## Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGsOiF2sMzat"
      },
      "source": [
        "EPOCHS = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 2e-5"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFLpR6laMzat"
      },
      "source": [
        "class ClassicalBertClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassicalBertClassifier, self).__init__()\n",
        "        \n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        \n",
        "        # BERT-base has 768 Output dimensions --> Map to 3 -> negative, neutral, positive\n",
        "        self.out = nn.Linear(768, 3)\n",
        "        self.all_targets = []\n",
        "        \n",
        "        # Binary Cross Entropy Loss combined with Sigmoid Layer\n",
        "        self.train_loss_fn = nn.BCEWithLogitsLoss()\n",
        "        self.valid_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids) -> torch.Tensor:\n",
        "        _, output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        output = self.drop(output)\n",
        "        output = self.out(output)\n",
        "        return output\n",
        "\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5kzP6NWMzau"
      },
      "source": [
        "## Set model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5GNevOAMzau"
      },
      "source": [
        "# now in training loop"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzl2n2sgMzau"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEqZP6V0zRB_"
      },
      "source": [
        "### Define optimizer, loss function and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC7p4gE3Mzau"
      },
      "source": [
        "# now in training loop"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYnMDrgtzaWt"
      },
      "source": [
        "### Define traditional training epoch (supervised)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dm68sAkMzau"
      },
      "source": [
        "def traditional_train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples):\n",
        "\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"ids\"].to(device)\n",
        "    attention_mask = d[\"mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "    token_type_ids = d['token_type_ids'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      ids=input_ids,\n",
        "      mask=attention_mask,\n",
        "      token_type_ids=token_type_ids)\n",
        "    \n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # set grad to 0\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # avoid exploding gradient\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFMWLRx41d-4"
      },
      "source": [
        "## Define traditional eval epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr60XpqfPca-"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"ids\"].to(device)\n",
        "      attention_mask = d[\"mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      token_type_ids = d['token_type_ids'].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        ids=input_ids,\n",
        "        mask=attention_mask,\n",
        "        token_type_ids=token_type_ids)\n",
        "      \n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdIM8YECp3Bn"
      },
      "source": [
        "## Define Pseudo Labeling Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5IJhJRJp5ui"
      },
      "source": [
        "def generate_pseudo_label(unlabeled_dataset, model):\n",
        "  # set model to eval mode\n",
        "  model.eval()\n",
        "  \n",
        "  pseudo_labels = []\n",
        "\n",
        "  for unlabeled_article in unlabeled_dataset:\n",
        "    # prepare data fro model\n",
        "    inputs = tokenizer.encode_plus(\n",
        "            unlabeled_article,\n",
        "            max_length=MAX_LEN,\n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "    ids = inputs['input_ids'].to(device)\n",
        "    mask = inputs['attention_mask'].to(device)\n",
        "    token_type_ids = inputs['token_type_ids'].to(device)\n",
        "\n",
        "    # calculate model outputs\n",
        "    output = model(\n",
        "      ids=ids,\n",
        "      mask=mask,\n",
        "      token_type_ids=token_type_ids)\n",
        "    \n",
        "    # calculate pseudo labels\n",
        "    _, pred = torch.max(output, dim=1)\n",
        "\n",
        "    pseudo_labels.append(pred.item())\n",
        "  \n",
        "  return pseudo_labels"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GABnMc4a10tP"
      },
      "source": [
        "## Define Naive Semi supervised deep learning training epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so8Bu_QR17x8"
      },
      "source": [
        "def nssdl_train_epoch(\n",
        "  model,\n",
        "  unlabeled_dataset,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  scheduler,\n",
        "  device,\n",
        "  n_examples):\n",
        "\n",
        "  # apply pseudo labeling\n",
        "  # 1. guess pseudo label\n",
        "  # 2. BertData()\n",
        "  # 3. DataLoader(BertData(PL))\n",
        "  # 4. concat\n",
        "\n",
        "  pseudo_labels = generate_pseudo_label(unlabeled_dataset=unlabeled_dataset, \n",
        "                                        model=model)\n",
        "  print(pseudo_labels[0])\n",
        "\n",
        "  # Convert to BertData\n",
        "  pseudo_labeled_dataset = BertData(article=unlabeled_dataset, \n",
        "                                    label=pseudo_labels)\n",
        "\n",
        "  # Create PseudoLabel DataLoader\n",
        "  pseudo_label_dataloader = DataLoader(\n",
        "            pseudo_labeled_dataset,\n",
        "            shuffle=False,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_workers=4\n",
        "            )\n",
        "\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in pseudo_label_dataloader:\n",
        "    input_ids = d[\"ids\"].to(device)\n",
        "    attention_mask = d[\"mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "    token_type_ids = d['token_type_ids'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      ids=input_ids,\n",
        "      mask=attention_mask,\n",
        "      token_type_ids=token_type_ids)\n",
        "    \n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # avoid exploding gradient\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBzofDQZ18Ey"
      },
      "source": [
        "## Define Naive Semi supervised deep eval training epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzPEI95Y1-Zy"
      },
      "source": [
        "# Sharing same eval loader as traditional approach"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2gpM7HR-YUb"
      },
      "source": [
        "## Generic Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtVBC5SS-b6N"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def run_model_training(kind, model, train_dataloader, val_dataloader, loss_fn, \n",
        "                       optimizer, scheduler, training_set, validation_set, \n",
        "                       unlabeled_train_set, unlabeled_scheduler): # kind == 'traditional', 'NSSDL', 'MixMatch'\n",
        "  best_accuracy = 0\n",
        "  history = defaultdict(list)\n",
        "  best_model = None\n",
        "\n",
        "  # for early stopping: save val_loss from last epoch\n",
        "  last_val_loss = None\n",
        "\n",
        "  # for precise analysis save pl acc/loss and finetune acc/loss as well\n",
        "  if kind == 'NSSDL':\n",
        "    train_acc_pl = 0\n",
        "    train_acc_fine_tune = 0\n",
        "    train_loss_pl = 0\n",
        "    train_loss_fine_tune = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    if kind == 'traditional':\n",
        "      train_acc, train_loss = traditional_train_epoch(\n",
        "        model=model,\n",
        "        data_loader=train_dataloader,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        scheduler=scheduler,\n",
        "        n_examples=len(training_set))\n",
        "      \n",
        "    if kind == 'NSSDL':\n",
        "      if epoch == 0:\n",
        "        # train initial model with labeled data\n",
        "        temp_acc, temp_loss = traditional_train_epoch(\n",
        "                model=model,\n",
        "                data_loader=train_dataloader,\n",
        "                loss_fn=loss_fn,\n",
        "                optimizer=optimizer,\n",
        "                device=device,\n",
        "                scheduler=scheduler,\n",
        "                n_examples=len(training_set)\n",
        "              )\n",
        "        print(f'Initial acc: {temp_acc}     Initial loss: {temp_loss}' )\n",
        "        \n",
        "      # first train with pseudo labels\n",
        "      train_acc_pl, train_loss_pl = nssdl_train_epoch(\n",
        "                model=model,\n",
        "                unlabeled_dataset=unlabeled_train_set,\n",
        "                loss_fn=loss_fn,\n",
        "                optimizer=optimizer,\n",
        "                device=device,\n",
        "                scheduler=unlabeled_scheduler,\n",
        "                n_examples=len(unlabeled_train_set)\n",
        "              )\n",
        "\n",
        "      # fine tune model with labeled samples\n",
        "      train_acc_fine_tune, train_loss_fine_tune = traditional_train_epoch(\n",
        "                model=model,\n",
        "                data_loader=train_dataloader,\n",
        "                loss_fn=loss_fn,\n",
        "                optimizer=optimizer,\n",
        "                device=device,\n",
        "                scheduler=scheduler,\n",
        "                n_examples=len(training_set)\n",
        "              )\n",
        "      \n",
        "      train_loss = (train_loss_pl + train_loss_fine_tune)/2\n",
        "      train_acc = (int(train_acc_pl) + int(train_acc_fine_tune))/2\n",
        "      print(\"PL Loss: \" + str(train_loss_pl) + \" Finetune Loss: \" + str(train_loss_fine_tune))\n",
        "      print(\"PL acc: \" + str(train_acc_pl) + \" Finetune acc: \" + str(train_acc_fine_tune))\n",
        "    \n",
        "    \n",
        "    print(f'({kind}) Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "      model,\n",
        "      val_dataloader,\n",
        "      loss_fn,\n",
        "      device,\n",
        "      len(validation_set))\n",
        "\n",
        "    \n",
        "    print(f'({kind}) Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if kind == 'NSSDL':\n",
        "      history['train_acc_pl'].append(train_acc)\n",
        "      history['train_acc_fine_tune'].append(train_acc_fine_tune)\n",
        "      history['train_loss_pl'].append(train_loss_pl)\n",
        "      history['train_loss_fine_tune'].append(train_loss_fine_tune)\n",
        "      \n",
        "    # early stopping:\n",
        "    if (last_val_loss is not None) and (last_val_loss < val_loss):\n",
        "      print(\"Early stopping executed due to increasing val_loss from \" + str(last_val_loss) + \" to \" + str(val_loss))\n",
        "      break\n",
        "\n",
        "    last_val_loss = val_loss\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "      best_model = model.state_dict()\n",
        "      torch.save(model.state_dict(), kind+'_best_model_state.bin')\n",
        "      best_accuracy = val_acc\n",
        "\n",
        "  return best_model, history, best_accuracy"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfaRm4ZxGtm9"
      },
      "source": [
        "## Overall Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "LHeiGlkTGs7u",
        "outputId": "d077aaf5-28b9-4cba-bfa3-2dd8692049d3"
      },
      "source": [
        "FOLDS = 10\n",
        "RANDOM_STATES = ['1210', '505', '2506', '1807', '1402', '107', '1803', '2405', '208', '2209']\n",
        "\n",
        "overall_saving_dict = {\n",
        "    'trad': [],\n",
        "    'nssdl': [],\n",
        "    'mixmatch': []\n",
        "}\n",
        "\n",
        "best_models = {\n",
        "    'trad': [],\n",
        "    'nssdl': [],\n",
        "    'mixmatch': []\n",
        "}\n",
        "\n",
        "\n",
        "# set reasonable data manipulation classes\n",
        "data_manipultation_classes = [50, 100, 250, 500, 2000]\n",
        "\n",
        "for data_class in data_manipultation_classes:\n",
        "  print(\"Data class of \" + str(data_class) + \" labeled samples per fold\")\n",
        "  print('-' * 50)\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "  for fold in range(FOLDS):\n",
        "    print(f'Fold {fold + 1}/{FOLDS}')\n",
        "    print('-' * 10)\n",
        "    print()\n",
        "\n",
        "    tradi_model = ClassicalBertClassifier()\n",
        "    tradi_model = tradi_model.to(device)\n",
        "\n",
        "    NSSDL_model = ClassicalBertClassifier()\n",
        "    NSSDL_model = NSSDL_model.to(device)\n",
        "\n",
        "    # set random_state\n",
        "    random_state = int(str(data_manipultation_classes.index(data_class)+1) + RANDOM_STATES[fold])\n",
        "\n",
        "    # set labeled- and unlabeled data and train-, val-, test data\n",
        "    split_data = split_data_into_train_test_val(data['article'], data['label'], 0.2, random_state)\n",
        "\n",
        "    X_train = split_data['train']['X']\n",
        "    X_test = split_data['test']['X']\n",
        "    X_val = split_data['val']['X']\n",
        "\n",
        "    y_train = split_data['train']['y']\n",
        "    y_test = split_data['test']['y']\n",
        "    y_val = split_data['val']['y']\n",
        "\n",
        "    data_dict = get_dataclass_distribution_of_unlabeled_data(data_class_size=data_class,\n",
        "                                                             X=X_train, \n",
        "                                                             y=y_train, \n",
        "                                                             random_state=random_state)\n",
        "    \n",
        "    X_train_labeled = data_dict['labeled_data']\n",
        "    X_train_unlabeled = data_dict['unlabeled_data']\n",
        "\n",
        "    y_train_labeled = data_dict['labeled_data_labels']\n",
        "    y_train_unlabeled = data_dict['unlabeled_data_labels'] # for testing purposes (maybe)\n",
        "\n",
        "    # initialise BertData\n",
        "    training_set = BertData(article=X_train_labeled, label=y_train_labeled)\n",
        "    validation_set = BertData(article=X_val, label=y_val)\n",
        "    test_set = BertData(article=X_test, label=y_test)\n",
        "\n",
        "    # initialize dataloaders\n",
        "    train_dataloader, val_dataloader, test_dataloader = get_dataloader(training_set, \n",
        "                                                                       validation_set, \n",
        "                                                                       test_set)\n",
        "\n",
        "    # define optimizers, schedulers and loss function\n",
        "    tradi_optimizer = transformers.AdamW(tradi_model.parameters(), lr=learning_rate, correct_bias=False)\n",
        "    nssdl_optimizer = transformers.AdamW(NSSDL_model.parameters(), lr=learning_rate, correct_bias=False)\n",
        "\n",
        "    total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "    tradi_labeled_scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "      tradi_optimizer,\n",
        "      num_warmup_steps=0,\n",
        "      num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    nssdl_labeled_scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "      nssdl_optimizer,\n",
        "      num_warmup_steps=0,\n",
        "      num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    nssdl_unlabeled_scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "      nssdl_optimizer,\n",
        "      num_warmup_steps=0,\n",
        "      num_training_steps=len(X_train_unlabeled)/BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    # train trad\n",
        "    tradi_best_model, tradi_history, tradi_best_acc = run_model_training('traditional', \n",
        "                                                         tradi_model, \n",
        "                                                         train_dataloader, \n",
        "                                                         val_dataloader, \n",
        "                                                         loss_fn, \n",
        "                                                         tradi_optimizer, \n",
        "                                                         tradi_labeled_scheduler, \n",
        "                                                         training_set, \n",
        "                                                         validation_set,\n",
        "                                                         X_train_unlabeled,\n",
        "                                                         None)\n",
        "\n",
        "\n",
        "    # train nssdl\n",
        "    nssdl_best_model, nssdl_history, nssdl_best_acc = run_model_training('NSSDL', \n",
        "                                                         NSSDL_model, \n",
        "                                                         train_dataloader, \n",
        "                                                         val_dataloader, \n",
        "                                                         loss_fn, \n",
        "                                                         nssdl_optimizer, \n",
        "                                                         nssdl_labeled_scheduler, \n",
        "                                                         training_set, \n",
        "                                                         validation_set,\n",
        "                                                         X_train_unlabeled,\n",
        "                                                         nssdl_unlabeled_scheduler)\n",
        "    \n",
        "\n",
        "\n",
        "    # train mixmatch\n",
        "\n",
        "\n",
        "    # execute evaluation with test set\n",
        "    # ---> Log locally\n",
        "\n",
        "    overall_saving_dict['trad'].append(tradi_history)\n",
        "    overall_saving_dict['nssdl'].append(nssdl_history)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # calc mean of logged results\n",
        "\n",
        "  # significance testing"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data class of 50 labeled samples per fold\n",
            "--------------------------------------------------\n",
            "\n",
            "Fold 1/10\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-4660c7f4e979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m                                                          \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                                          \u001b[0mX_train_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                                          None)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-fb06fd57e3a9>\u001b[0m in \u001b[0;36mrun_model_training\u001b[0;34m(kind, model, train_dataloader, val_dataloader, loss_fn, optimizer, scheduler, training_set, validation_set, unlabeled_train_set, unlabeled_scheduler)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         n_examples=len(training_set))\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NSSDL'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-7999b9cf4623>\u001b[0m in \u001b[0;36mtraditional_train_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-e2bfcb839352>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 13.99 GiB already allocated; 27.75 MiB free; 14.97 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKRmOxXl1LYe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNXbuBWF-mI_"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcAx_lP9Si2c"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_dataloader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(test_set)\n",
        ")\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkzkVJT2SqWc"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"article\"]\n",
        "      input_ids = d[\"ids\"].to(device)\n",
        "      attention_mask = d[\"mask\"].to(device)\n",
        "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        ids=input_ids,\n",
        "        mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "      )\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsh1HoYHSuWU"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_dataloader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVNbnvjrSuqz"
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=label_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJfGxOmUYTi"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index=label_names, columns=label_names)\n",
        "\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmqT5sToXrcb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crte907NuVqx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}