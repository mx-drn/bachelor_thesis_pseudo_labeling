Fold: 9

Traditional:
-----------
(Traditional) Epoch 1: 
 Training(acc: 0.34, precision: 0.3841, recall: 0.3419117647058824, f1: 0.31648351648351647, loss: 1.1039) 
 Validation(acc: 0.3681, precision: 0.3571, recall: 0.3670857401744252, f1: 0.31156973108192615, loss: 1.1136)

(Traditional) Epoch 2: 
 Training(acc: 0.4, precision: 0.4511, recall: 0.400735294117647, f1: 0.4068376068376068, loss: 1.1001) 
 Validation(acc: 0.3804, precision: 0.3897, recall: 0.3794031034092196, f1: 0.331823075955856, loss: 1.1053)

(Traditional) Epoch 3: 
 Training(acc: 0.38, precision: 0.3843, recall: 0.3811274509803922, f1: 0.3489781536293164, loss: 1.0622) 
 Validation(acc: 0.3957, precision: 0.3868, recall: 0.3948635179522029, f1: 0.3608214858214858, loss: 1.0956)

(Traditional) Epoch 4: 
 Training(acc: 0.4, precision: 0.4209, recall: 0.40196078431372545, f1: 0.3999776548796157, loss: 1.0679) 
 Validation(acc: 0.4448, precision: 0.4514, recall: 0.44427454977913694, f1: 0.41657569803265165, loss: 1.0884)

(Traditional) Epoch 5: 
 Training(acc: 0.62, precision: 0.6297, recall: 0.6164215686274509, f1: 0.6117283950617285, loss: 0.93) 
 Validation(acc: 0.4417, precision: 0.4567, recall: 0.44132970891380685, f1: 0.4050927919908884, loss: 1.0841)

(Traditional) Epoch 6: 
 Training(acc: 0.62, precision: 0.6186, recall: 0.6151960784313726, f1: 0.6028657616892911, loss: 0.9211) 
 Validation(acc: 0.4387, precision: 0.443, recall: 0.4385547627137841, f1: 0.40184331797235023, loss: 1.079)

(Traditional) Epoch 7: 
 Training(acc: 0.64, precision: 0.6832, recall: 0.636029411764706, f1: 0.6328875968992248, loss: 0.8946) 
 Validation(acc: 0.4479, precision: 0.4518, recall: 0.44755917997508216, f1: 0.40505911102305, loss: 1.0759)

(Traditional) Epoch 8: 
 Training(acc: 0.8, precision: 0.8166, recall: 0.7990196078431372, f1: 0.8016462263286219, loss: 0.8429) 
 Validation(acc: 0.4479, precision: 0.4267, recall: 0.44758749575263335, f1: 0.4049152362458021, loss: 1.07)

(Traditional) Epoch 9: 
 Training(acc: 0.76, precision: 0.7702, recall: 0.7573529411764706, f1: 0.7540237540237541, loss: 0.7799) 
 Validation(acc: 0.4509, precision: 0.4284, recall: 0.4505323366179635, f1: 0.4143234326384509, loss: 1.0609)

(Traditional) Epoch 10: 
 Training(acc: 0.9, precision: 0.904, recall: 0.8982843137254902, f1: 0.8989106753812636, loss: 0.7025) 
 Validation(acc: 0.4847, precision: 0.4771, recall: 0.4840865330161967, f1: 0.45972933560961726, loss: 1.0457)

-----------------------------------------------------------------

NSSDL:
-----------
(NSSDL) Epoch 1: 
 Training(acc: 0.5875, precision: 0.401, recall: 0.3689220347452984, f1: 0.30707240379678985, loss: 2.1109) 
 Validation(acc: 0.3834, precision: 0.2605, recall: 0.382262996941896, f1: 0.2706094343265332, loss: 1.4071)
PL-Training(acc: 0.7951, precision: 0.4662, recall: 0.34691269694157717, f1: 0.3315361119414058, loss: 0.6421) 
 Finetune-Training(acc: 0.38, precision: 0.3359, recall: 0.3909313725490196, f1: 0.2826086956521739, loss: 1.4688)

(NSSDL) Epoch 2: 
 Training(acc: 0.6174, precision: 0.3367, recall: 0.4329100141011645, f1: 0.35778381888492755, loss: 3.462) 
 Validation(acc: 0.3313, precision: 0.1672, recall: 0.4954128440366973, f1: 0.24999999999999994, loss: 1.2629)
PL-Training(acc: 0.8947, precision: 0.5578, recall: 0.5324866948689956, f1: 0.5438504660526834, loss: 0.3164) 
 Finetune-Training(acc: 0.34, precision: 0.1156, recall: 0.3333333333333333, f1: 0.1717171717171717, loss: 3.1456)

(NSSDL) Epoch 3: 
 Training(acc: 0.6504, precision: 0.2991, recall: 0.41605839416058393, f1: 0.32839262187088275, loss: 5.0202) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 2.6288)
PL-Training(acc: 0.9809, precision: 0.4916, recall: 0.49878345498783455, f1: 0.49516908212560384, loss: 0.1085) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 4.9117)

(NSSDL) Epoch 4: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.9878) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 4.7014)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0028) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.985)

(NSSDL) Epoch 5: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.3233) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 4.865)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0016) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.3217)

(NSSDL) Epoch 6: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.5226) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 4.9104)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0019) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.5207)

(NSSDL) Epoch 7: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.0881) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 4.9199)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0019) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.0862)

(NSSDL) Epoch 8: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.0449) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 5.0151)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0017) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.0432)

(NSSDL) Epoch 9: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 5.3607) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 5.0259)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0018) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 5.3589)

(NSSDL) Epoch 10: 
 Training(acc: 0.66, precision: 0.5533, recall: 0.6666666666666666, f1: 0.5808080808080808, loss: 4.9584) 
 Validation(acc: 0.3344, precision: 0.3344, recall: 1.0, f1: 0.5011494252873563, loss: 4.8445)
PL-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0017) 
 Finetune-Training(acc: 0.32, precision: 0.1067, recall: 0.3333333333333333, f1: 0.16161616161616163, loss: 4.9567)

-----------------------------------------------------------------
-----------
NSSDL_Strong:
(NSSDL  Strong) Epoch 1: 
 Training(acc: 0.9589, precision: 0.9557, recall: 0.9564426991370709, f1: 0.9560636020366065, loss: 0.2178) 
 Validation(acc: 0.589, precision: 0.5902, recall: 0.5884018575150073, f1: 0.583966270784663, loss: 3.0564)
PL-Training(acc: 0.9179, precision: 0.9114, recall: 0.9128853982741418, f1: 0.9121272040732128, loss: 0.2175) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0003)

(NSSDL  Strong) Epoch 2: 
 Training(acc: 0.9729, precision: 0.9714, recall: 0.9708845808579964, f1: 0.97111406726393, loss: 0.1742) 
 Validation(acc: 0.589, precision: 0.5899, recall: 0.5884301732925586, f1: 0.5842755861061301, loss: 3.1423)
PL-Training(acc: 0.9458, precision: 0.9427, recall: 0.9417691617159929, f1: 0.94222813452786, loss: 0.174) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0002)

(NSSDL  Strong) Epoch 3: 
 Training(acc: 0.9848, precision: 0.9841, recall: 0.9841534753994465, f1: 0.9841132116012397, loss: 0.0962) 
 Validation(acc: 0.589, precision: 0.586, recall: 0.5884018575150073, f1: 0.5816971699324641, loss: 3.394)
PL-Training(acc: 0.9697, precision: 0.9682, recall: 0.9683069507988931, f1: 0.9682264232024793, loss: 0.0961) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0002)

(NSSDL  Strong) Epoch 4: 
 Training(acc: 0.9868, precision: 0.9861, recall: 0.9866689601387084, f1: 0.9863899922053798, loss: 0.0812) 
 Validation(acc: 0.592, precision: 0.5871, recall: 0.5914599614905426, f1: 0.5841892883345562, loss: 3.4958)
PL-Training(acc: 0.9737, precision: 0.9722, recall: 0.9733379202774167, f1: 0.9727799844107597, loss: 0.081) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 5: 
 Training(acc: 0.9932, precision: 0.9931, recall: 0.993173116022185, f1: 0.9931259180202372, loss: 0.0594) 
 Validation(acc: 0.5859, precision: 0.5809, recall: 0.585315437761921, f1: 0.5759368150789673, loss: 3.6516)
PL-Training(acc: 0.9864, precision: 0.9862, recall: 0.98634623204437, f1: 0.9862518360404744, loss: 0.0593) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 6: 
 Training(acc: 0.9956, precision: 0.9957, recall: 0.9955091411564625, f1: 0.9955839392048744, loss: 0.0339) 
 Validation(acc: 0.592, precision: 0.5875, recall: 0.5914316457129912, f1: 0.5836090432864626, loss: 3.6804)
PL-Training(acc: 0.9912, precision: 0.9913, recall: 0.9910182823129251, f1: 0.9911678784097487, loss: 0.0338) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 7: 
 Training(acc: 0.9936, precision: 0.9935, recall: 0.9926617338916752, f1: 0.9930863265631336, loss: 0.0452) 
 Validation(acc: 0.5951, precision: 0.5916, recall: 0.5946030127987315, f1: 0.5885118084113333, loss: 3.8132)
PL-Training(acc: 0.9872, precision: 0.9871, recall: 0.9853234677833504, f1: 0.986172653126267, loss: 0.0451) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 8: 
 Training(acc: 0.9944, precision: 0.9943, recall: 0.9937917776509386, f1: 0.994030398638827, loss: 0.0497) 
 Validation(acc: 0.5982, precision: 0.6021, recall: 0.5976044852191641, f1: 0.5934813576615657, loss: 3.9202)
PL-Training(acc: 0.9888, precision: 0.9885, recall: 0.9875835553018772, f1: 0.988060797277654, loss: 0.0496) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 9: 
 Training(acc: 0.996, precision: 0.9956, recall: 0.996072726771698, f1: 0.9958282313686777, loss: 0.0408) 
 Validation(acc: 0.5706, precision: 0.5664, recall: 0.5699682863291425, f1: 0.5603457444461629, loss: 4.0149)
PL-Training(acc: 0.992, precision: 0.9912, recall: 0.9921454535433961, f1: 0.9916564627373555, loss: 0.0407) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

(NSSDL  Strong) Epoch 10: 
 Training(acc: 0.998, precision: 0.9982, recall: 0.9980363633858491, f1: 0.9981376739598453, loss: 0.0104) 
 Validation(acc: 0.592, precision: 0.5929, recall: 0.5914316457129912, f1: 0.5852363566329509, loss: 4.0205)
PL-Training(acc: 0.996, precision: 0.9965, recall: 0.9960727267716981, f1: 0.9962753479196905, loss: 0.0104) 
 Finetune-Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0001)

-----------------------------------------------------------------
-----------
MixText:
(MixText) Epoch 1: 
 Training(acc: 0.78, precision: 0.7904, recall: 0.7794117647058822, f1: 0.7812533941566199, loss: 0.9052) 
 Validation(acc: 0.3957, precision: 0.4161, recall: 0.3964775172726243, f1: 0.3785613159846289, loss: 1.0812)

(MixText) Epoch 2: 
 Training(acc: 0.92, precision: 0.9191, recall: 0.9191176470588235, f1: 0.9191176470588235, loss: 0.4695) 
 Validation(acc: 0.4264, precision: 0.414, recall: 0.426605504587156, f1: 0.41130819170746574, loss: 1.0895)

(MixText) Epoch 3: 
 Training(acc: 0.98, precision: 0.9804, recall: 0.9803921568627452, f1: 0.9797979797979798, loss: 0.1833) 
 Validation(acc: 0.408, precision: 0.4179, recall: 0.4085117227319062, f1: 0.39807879391049683, loss: 1.2378)

(MixText) Epoch 4: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.122) 
 Validation(acc: 0.3957, precision: 0.4386, recall: 0.3967606750481368, f1: 0.36209613869188334, loss: 1.4352)

(MixText) Epoch 5: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0724) 
 Validation(acc: 0.3865, precision: 0.393, recall: 0.3873881526786726, f1: 0.3617837747012518, loss: 1.5444)

(MixText) Epoch 6: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.1005) 
 Validation(acc: 0.4049, precision: 0.4261, recall: 0.4061048816400499, f1: 0.36324762705130803, loss: 1.4062)

(MixText) Epoch 7: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0862) 
 Validation(acc: 0.3834, precision: 0.4388, recall: 0.3848114169215087, f1: 0.32661429679603854, loss: 1.6112)

(MixText) Epoch 8: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0552) 
 Validation(acc: 0.4049, precision: 0.4266, recall: 0.406019934307396, f1: 0.3702464177698448, loss: 1.7485)

(MixText) Epoch 9: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0595) 
 Validation(acc: 0.3865, precision: 0.4567, recall: 0.3880394155623514, f1: 0.3154600929200471, loss: 2.0578)

(MixText) Epoch 10: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0548) 
 Validation(acc: 0.3896, precision: 0.4701, recall: 0.39104088798278397, f1: 0.32548307256310144, loss: 2.2133)

(MixText) Epoch 11: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0624) 
 Validation(acc: 0.3957, precision: 0.4767, recall: 0.39715709593385434, f1: 0.3345431619941424, loss: 2.0701)

(MixText) Epoch 12: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0758) 
 Validation(acc: 0.3957, precision: 0.4658, recall: 0.3972420432665081, f1: 0.3263328369019426, loss: 1.9989)

(MixText) Epoch 13: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0556) 
 Validation(acc: 0.3896, precision: 0.4626, recall: 0.3910692037603353, f1: 0.3228125572042345, loss: 2.4226)

(MixText) Epoch 14: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0537) 
 Validation(acc: 0.3896, precision: 0.4678, recall: 0.39098425642768153, f1: 0.3294182503943919, loss: 2.1184)

(MixText) Epoch 15: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0429) 
 Validation(acc: 0.4018, precision: 0.4828, recall: 0.4033016196624759, f1: 0.3411386593204775, loss: 2.4246)

(MixText) Epoch 16: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0373) 
 Validation(acc: 0.3926, precision: 0.4677, recall: 0.39398572884811417, f1: 0.3392881423305892, loss: 2.379)

(MixText) Epoch 17: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0342) 
 Validation(acc: 0.3988, precision: 0.4803, recall: 0.4000736210216333, f1: 0.3471316492731061, loss: 2.5056)

(MixText) Epoch 18: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0266) 
 Validation(acc: 0.4049, precision: 0.4879, recall: 0.4061615131951523, f1: 0.35740980357871427, loss: 2.5029)

(MixText) Epoch 19: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0343) 
 Validation(acc: 0.3865, precision: 0.4607, recall: 0.3878695208970439, f1: 0.3311648913668129, loss: 2.5803)

(MixText) Epoch 20: 
 Training(acc: 1.0, precision: 1.0, recall: 1.0, f1: 1.0, loss: 0.0187) 
 Validation(acc: 0.3926, precision: 0.4581, recall: 0.3940140446256654, f1: 0.33627668082626316, loss: 2.9504)

-----------------------------------------------------------------


+++++++++++++++++++++++++++++++++++